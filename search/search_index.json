{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Pymetrix What is Pymetrix? Pymetrix (previously known as Analyx ) is a plug-and-play analytics library written in Python. How to use it Pymetrix is really easy to integrate with your projects. Here's an example: Let's say you want to monitor a method foo() defined as: from random import randint def foo (): print ( f \"Hello world { randint ( 0 , 1000000 ) } !\" ) After adding the required lines, the code will look something like this: from random import randint from pymetrix.metrics import Metrics metricman = Metrics ( loc = __file__ ) foo_obj = None def foo (): print ( f \"Hello world { randint ( 0 , 1000000 ) } !\" ) if foo_obj is None : ep1 = endpoints . Endpoint ( endpoint = \"/\" , id = foo ) foo_obj = flow . FlowNode ( ep1 , name = \"Object1\" ) metricman . add_to_analytics ( foo_obj , layerName = \"foo\" ) Using with various Web Frameworks Pymetrix can be used in conjunction with other frameworks as well, including web frameworks. The following examples will illustrate it more clearly. 1. Using with Django Django is the most popular framework of choice for a vast majority of Python web developers, often dubbed as \"the framework for perfectionists with deadlines\". It is a clean, concise and opinionated framework that enforces code reusability, modularity and code readability. It has an intuitive directory structure, and a large ecosystem of plugins tailor-made for it. Besides those, the usual Python libraries that can be used in tandem with it for designing business logic as well. Being a library, you can import Pymetrix on any file that will be executed by the server on calling the endpoints. This is usually the views.py file in a standard Django project. A sample views.py in Django with Pymetrix (Tested on Django 4.0.0): from django.shortcuts import render , HttpResponse from django.http import StreamingHttpResponse from typing import Dict , List , Any , Tuple , NewType from pymetrix import metrics , endpoints , flow import pymetrix.visualize as vs # Create your views here. metricman = metrics . Metrics ( loc = \"Test\" ) # Initialize the Pymetrix Metrics object def blog ( request ): # Other code ... node2 : flow . FlowNodeType = flow . FlowNode ( endpoints . Endpoint ( endpoint = \"/blog\" , id = blog ), name = \"Blog\" ) metricman . add_to_analytics ( node2 ) # Add the function to the graph corresponding to the metricman object # any return stuff return HttpResponse ( \"<h1>Blog works!</h1>\" ) def about ( request ): # Other code ... node3 : flow . FlowNodeType = flow . FlowNode ( endpoints . Endpoint ( endpoint = \"/about\" , id = about ), name = \"About\" ) metricman . add_to_analytics ( node3 ) # Add the function to the graph corresponding to the metricman object # any return stuff return HttpResponse ( \"<h1>About works!</h1>\" ) def contact ( request ): # Other code ... node4 : flow . FlowNodeType = flow . FlowNode ( endpoints . Endpoint ( endpoint = \"/contact\" , id = contact ), name = \"Contact\" ) metricman . add_to_analytics ( node4 ) # Add the function to the graph corresponding to the metricman object # any return stuff return HttpResponse ( \"<h1>Contact works!</h1>\" ) def collaborations ( request ): # Other code ... node6 : flow . FlowNodeType = flow . FlowNode ( endpoints . Endpoint ( endpoint = \"/collaborations\" , id = collaborations ), name = \"Collaborations\" , ) metricman . add_to_analytics ( node6 ) # Add the function to the graph corresponding to the metricman object # any return stuff return HttpResponse ( \"<h1>Collaborations works!</h1>\" ) def events ( request ): # Other code ... node5 : flow . FlowNodeType = flow . FlowNode ( endpoints . Endpoint ( endpoint = \"/events\" , id = events ), name = \"Events\" ) metricman . add_to_analytics ( node5 ) # Add the function to the graph corresponding to the metricman object # any return stuff return HttpResponse ( \"<h1>Events works!</h1>\" ) def home ( request ): node1 : flow . FlowNodeType = flow . FlowNode ( endpoints . Endpoint ( endpoint = \"/home1\" , id = home ), name = \"Home\" ) metricman . add_to_analytics ( node1 ) # Add the function to the graph corresponding to the metricman object return HttpResponse ( \"<h1>Home works!</h1>\" ) # The methods below won't be added for metrics def someMethod ( request ): ... class someClass : ... def anotherMethod ( request ): ... def aThirdMethod ( request ): ... Although I haven't tested it yet, owing to the nature of the metricman object, I think it can be used in the top level urls.py for being used over the entire project - one that has multiple Django Apps into it. Also, do check out Pymetrix Django Dashboard 2. Using with FastAPI FastAPI is a micro web framework built on top of Pydantic and Starlette. It claims to be the fastest Pythonic web framework out there for building APIs, and adheres to the OpenAPI standards. It provides two UIs for testing the APIs made through it - Redoc and SwaggerUI. It also provides a lot of functionalities out of the box, such as asynchronous calls, which speeds up API calls, sometimes tremendously. It can be used both with ASGI and WSGI. Integrating Pymetrix with FastAPI is as easy as it is in Django, if not easier. from fastapi import FastAPI , status from pymetrix import metrics , endpoints , flow from fastapi.responses import ORJSONResponse app = FastAPI () metricman = metrics . Metrics ( loc = \"Test\" ) @app . get ( \"/home\" , status_code = status . HTTP_200_OK , response_class = ORJSONResponse ) async def home (): node1 : flow . FlowNodeType = flow . FlowNode ( endpoints . Endpoint ( endpoint = \"/home\" , id = home ), name = \"Home\" ) metricman . add_to_analytics ( node1 ) return { \"response\" : status . HTTP_200_OK , \"message\" : \"This is the home page\" } @app . get ( \"/contact\" , status_code = status . HTTP_200_OK , response_class = ORJSONResponse ) async def contact (): node2 : flow . FlowNodeType = flow . FlowNode ( endpoints . Endpoint ( endpoint = \"/contact\" , id = contact ), name = \"Contact\" ) metricman . add_to_analytics ( node2 ) return { \"response\" : status . HTTP_200_OK , \"message\" : \"This is the contact page\" } @app . get ( \"/collaborations\" , status_code = status . HTTP_200_OK , response_class = ORJSONResponse ) async def collaborations (): node3 : flow . FlowNodeType = flow . FlowNode ( endpoints . Endpoint ( endpoint = \"/collaborations\" , id = collaborations ), name = \"Collaborations\" , ) metricman . add_to_analytics ( node3 ) return { \"response\" : status . HTTP_200_OK , \"message\" : \"This is the collaborations page\" , } @app . get ( \"/events\" , status_code = status . HTTP_200_OK , response_class = ORJSONResponse ) async def events (): node4 : flow . FlowNodeType = flow . FlowNode ( endpoints . Endpoint ( endpoint = \"/events\" , id = events ), name = \"Events\" ) metricman . add_to_analytics ( node4 ) return { \"response\" : status . HTTP_200_OK , \"message\" : \"This is the events page\" } @app . get ( \"/blog\" , status_code = status . HTTP_200_OK , response_class = ORJSONResponse ) async def blog (): node5 : flow . FlowNodeType = flow . FlowNode ( endpoints . Endpoint ( endpoint = \"/blog\" , id = blog ), name = \"Blog\" ) metricman . add_to_analytics ( node5 ) return { \"response\" : status . HTTP_200_OK , \"message\" : \"This is the blog page\" } @app . get ( \"/about\" , status_code = status . HTTP_200_OK , response_class = ORJSONResponse ) async def about (): node6 : flow . FlowNodeType = flow . FlowNode ( endpoints . Endpoint ( endpoint = \"/about\" , id = about ), name = \"About\" ) metricman . add_to_analytics ( node6 ) return { \"response\" : status . HTTP_200_OK , \"message\" : \"This is the about page\" } @app . get ( \"/statistics\" , status_code = status . HTTP_200_OK , response_class = ORJSONResponse ) async def get_statistics (): return { \"response\" : status . HTTP_200_OK , \"message\" : metricman . aggregate ()} Now we start the uvicorn server using: uvicorn main:app --port 8000 --reload Now going to localhost:8000/statistics will give you the aggregate hits on each endpoint. Also, here we are serializing the data using orjson, instead of regular JSON Just like the case with Django, you can initialize a Pymetrix object in the main.py file and then import into other scripts from there, if you want a centralized view. But you're also free to take a modular approach with your project by initializing the Pymetrix objects within each module - your skills are your limit. 3. Using with Starlite Starlite is the new challenger in town for Web API frameworks. It's similar to FastAPI in the aspect that it's based on Starlette and Pydantic. But it has a fundamental philosophical difference - Starlite is opinionated, while FastAPI is not. According to the maker of Starlite, Na'aman Hirschfeld (who is also an online friend of mine \ud83d\ude0e): The intention behind Starlite was to create a higher level opinionated API framework. I placed opinionated in bold because in my view, being opinionated regarding how certain things should be done and shouldn\u2019t be done, and establishing best practices, is one of the most important things a framework can do. So let's see how Pymetrix works with Starlite: from starlite import Starlite , get from pymetrix import metrics , endpoints , flow from typing import Dict metricman = metrics . Metrics ( loc = \"Test\" ) @get ( path = \"/home\" ) def home () -> Dict : node1 : flow . FlowNodeType = flow . FlowNode ( endpoints . Endpoint ( endpoint = \"/home\" , id = home ), name = \"Home\" ) metricman . add_to_analytics ( node1 ) return { \"response\" : 200 , \"message\" : \"Home Page Works\" } @get ( path = \"/contact\" ) def contact () -> Dict : node2 : flow . FlowNodeType = flow . FlowNode ( endpoints . Endpoint ( endpoint = \"/contact\" , id = contact ), name = \"Contact\" ) metricman . add_to_analytics ( node2 ) return { \"response\" : 200 , \"message\" : \"Contact Page Works\" } @get ( path = \"/collaborations\" ) def collaborations () -> Dict : node3 : flow . FlowNodeType = flow . FlowNode ( endpoints . Endpoint ( endpoint = \"/collaborations\" , id = collaborations ), name = \"Collaborations\" , ) metricman . add_to_analytics ( node3 ) return { \"response\" : 200 , \"message\" : \"Collaborations Page Works\" } @get ( path = \"/events\" ) def events () -> Dict : node4 : flow . FlowNodeType = flow . FlowNode ( endpoints . Endpoint ( endpoint = \"/events\" , id = events ), name = \"Events\" ) metricman . add_to_analytics ( node4 ) return { \"response\" : 200 , \"message\" : \"Events Page Works\" } @get ( path = \"/blog\" ) def blog () -> Dict : node5 : flow . FlowNodeType = flow . FlowNode ( endpoints . Endpoint ( endpoint = \"/blog\" , id = blog ), name = \"Blog\" ) metricman . add_to_analytics ( node5 ) return { \"response\" : 200 , \"message\" : \"Blog Page Works\" } @get ( path = \"/about\" ) def about () -> Dict : node6 : flow . FlowNodeType = flow . FlowNode ( endpoints . Endpoint ( endpoint = \"/about\" , id = about ), name = \"About\" ) metricman . add_to_analytics ( node6 ) return { \"response\" : 200 , \"message\" : \"About Page Works\" } @get ( path = \"/statistics\" ) def statistics () -> Dict : node2 : flow . FlowNodeType = flow . FlowNode ( endpoints . Endpoint ( endpoint = \"/contact\" , id = contact ), name = \"Contact\" ) metricman . add_to_analytics ( node2 ) return { \"response\" : 200 , \"message\" : metricman . time_series ()} app = Starlite ( route_handlers = [ home , contact , collaborations , events , blog , about , statistics ] ) Do note that Starlite uses the orjson library for its responses by default. Orjson Note In orjson , the response is a JSON byte string and not a object. This dramatically speeds up the serialization process.","title":"Home"},{"location":"#pymetrix","text":"","title":"Pymetrix"},{"location":"#what-is-pymetrix","text":"Pymetrix (previously known as Analyx ) is a plug-and-play analytics library written in Python.","title":"What is Pymetrix?"},{"location":"#how-to-use-it","text":"Pymetrix is really easy to integrate with your projects. Here's an example: Let's say you want to monitor a method foo() defined as: from random import randint def foo (): print ( f \"Hello world { randint ( 0 , 1000000 ) } !\" ) After adding the required lines, the code will look something like this: from random import randint from pymetrix.metrics import Metrics metricman = Metrics ( loc = __file__ ) foo_obj = None def foo (): print ( f \"Hello world { randint ( 0 , 1000000 ) } !\" ) if foo_obj is None : ep1 = endpoints . Endpoint ( endpoint = \"/\" , id = foo ) foo_obj = flow . FlowNode ( ep1 , name = \"Object1\" ) metricman . add_to_analytics ( foo_obj , layerName = \"foo\" )","title":"How to use it"},{"location":"#using-with-various-web-frameworks","text":"Pymetrix can be used in conjunction with other frameworks as well, including web frameworks. The following examples will illustrate it more clearly.","title":"Using with various Web Frameworks"},{"location":"#1-using-with-django","text":"Django is the most popular framework of choice for a vast majority of Python web developers, often dubbed as \"the framework for perfectionists with deadlines\". It is a clean, concise and opinionated framework that enforces code reusability, modularity and code readability. It has an intuitive directory structure, and a large ecosystem of plugins tailor-made for it. Besides those, the usual Python libraries that can be used in tandem with it for designing business logic as well. Being a library, you can import Pymetrix on any file that will be executed by the server on calling the endpoints. This is usually the views.py file in a standard Django project. A sample views.py in Django with Pymetrix (Tested on Django 4.0.0): from django.shortcuts import render , HttpResponse from django.http import StreamingHttpResponse from typing import Dict , List , Any , Tuple , NewType from pymetrix import metrics , endpoints , flow import pymetrix.visualize as vs # Create your views here. metricman = metrics . Metrics ( loc = \"Test\" ) # Initialize the Pymetrix Metrics object def blog ( request ): # Other code ... node2 : flow . FlowNodeType = flow . FlowNode ( endpoints . Endpoint ( endpoint = \"/blog\" , id = blog ), name = \"Blog\" ) metricman . add_to_analytics ( node2 ) # Add the function to the graph corresponding to the metricman object # any return stuff return HttpResponse ( \"<h1>Blog works!</h1>\" ) def about ( request ): # Other code ... node3 : flow . FlowNodeType = flow . FlowNode ( endpoints . Endpoint ( endpoint = \"/about\" , id = about ), name = \"About\" ) metricman . add_to_analytics ( node3 ) # Add the function to the graph corresponding to the metricman object # any return stuff return HttpResponse ( \"<h1>About works!</h1>\" ) def contact ( request ): # Other code ... node4 : flow . FlowNodeType = flow . FlowNode ( endpoints . Endpoint ( endpoint = \"/contact\" , id = contact ), name = \"Contact\" ) metricman . add_to_analytics ( node4 ) # Add the function to the graph corresponding to the metricman object # any return stuff return HttpResponse ( \"<h1>Contact works!</h1>\" ) def collaborations ( request ): # Other code ... node6 : flow . FlowNodeType = flow . FlowNode ( endpoints . Endpoint ( endpoint = \"/collaborations\" , id = collaborations ), name = \"Collaborations\" , ) metricman . add_to_analytics ( node6 ) # Add the function to the graph corresponding to the metricman object # any return stuff return HttpResponse ( \"<h1>Collaborations works!</h1>\" ) def events ( request ): # Other code ... node5 : flow . FlowNodeType = flow . FlowNode ( endpoints . Endpoint ( endpoint = \"/events\" , id = events ), name = \"Events\" ) metricman . add_to_analytics ( node5 ) # Add the function to the graph corresponding to the metricman object # any return stuff return HttpResponse ( \"<h1>Events works!</h1>\" ) def home ( request ): node1 : flow . FlowNodeType = flow . FlowNode ( endpoints . Endpoint ( endpoint = \"/home1\" , id = home ), name = \"Home\" ) metricman . add_to_analytics ( node1 ) # Add the function to the graph corresponding to the metricman object return HttpResponse ( \"<h1>Home works!</h1>\" ) # The methods below won't be added for metrics def someMethod ( request ): ... class someClass : ... def anotherMethod ( request ): ... def aThirdMethod ( request ): ... Although I haven't tested it yet, owing to the nature of the metricman object, I think it can be used in the top level urls.py for being used over the entire project - one that has multiple Django Apps into it. Also, do check out Pymetrix Django Dashboard","title":"1. Using with Django"},{"location":"#2-using-with-fastapi","text":"FastAPI is a micro web framework built on top of Pydantic and Starlette. It claims to be the fastest Pythonic web framework out there for building APIs, and adheres to the OpenAPI standards. It provides two UIs for testing the APIs made through it - Redoc and SwaggerUI. It also provides a lot of functionalities out of the box, such as asynchronous calls, which speeds up API calls, sometimes tremendously. It can be used both with ASGI and WSGI. Integrating Pymetrix with FastAPI is as easy as it is in Django, if not easier. from fastapi import FastAPI , status from pymetrix import metrics , endpoints , flow from fastapi.responses import ORJSONResponse app = FastAPI () metricman = metrics . Metrics ( loc = \"Test\" ) @app . get ( \"/home\" , status_code = status . HTTP_200_OK , response_class = ORJSONResponse ) async def home (): node1 : flow . FlowNodeType = flow . FlowNode ( endpoints . Endpoint ( endpoint = \"/home\" , id = home ), name = \"Home\" ) metricman . add_to_analytics ( node1 ) return { \"response\" : status . HTTP_200_OK , \"message\" : \"This is the home page\" } @app . get ( \"/contact\" , status_code = status . HTTP_200_OK , response_class = ORJSONResponse ) async def contact (): node2 : flow . FlowNodeType = flow . FlowNode ( endpoints . Endpoint ( endpoint = \"/contact\" , id = contact ), name = \"Contact\" ) metricman . add_to_analytics ( node2 ) return { \"response\" : status . HTTP_200_OK , \"message\" : \"This is the contact page\" } @app . get ( \"/collaborations\" , status_code = status . HTTP_200_OK , response_class = ORJSONResponse ) async def collaborations (): node3 : flow . FlowNodeType = flow . FlowNode ( endpoints . Endpoint ( endpoint = \"/collaborations\" , id = collaborations ), name = \"Collaborations\" , ) metricman . add_to_analytics ( node3 ) return { \"response\" : status . HTTP_200_OK , \"message\" : \"This is the collaborations page\" , } @app . get ( \"/events\" , status_code = status . HTTP_200_OK , response_class = ORJSONResponse ) async def events (): node4 : flow . FlowNodeType = flow . FlowNode ( endpoints . Endpoint ( endpoint = \"/events\" , id = events ), name = \"Events\" ) metricman . add_to_analytics ( node4 ) return { \"response\" : status . HTTP_200_OK , \"message\" : \"This is the events page\" } @app . get ( \"/blog\" , status_code = status . HTTP_200_OK , response_class = ORJSONResponse ) async def blog (): node5 : flow . FlowNodeType = flow . FlowNode ( endpoints . Endpoint ( endpoint = \"/blog\" , id = blog ), name = \"Blog\" ) metricman . add_to_analytics ( node5 ) return { \"response\" : status . HTTP_200_OK , \"message\" : \"This is the blog page\" } @app . get ( \"/about\" , status_code = status . HTTP_200_OK , response_class = ORJSONResponse ) async def about (): node6 : flow . FlowNodeType = flow . FlowNode ( endpoints . Endpoint ( endpoint = \"/about\" , id = about ), name = \"About\" ) metricman . add_to_analytics ( node6 ) return { \"response\" : status . HTTP_200_OK , \"message\" : \"This is the about page\" } @app . get ( \"/statistics\" , status_code = status . HTTP_200_OK , response_class = ORJSONResponse ) async def get_statistics (): return { \"response\" : status . HTTP_200_OK , \"message\" : metricman . aggregate ()} Now we start the uvicorn server using: uvicorn main:app --port 8000 --reload Now going to localhost:8000/statistics will give you the aggregate hits on each endpoint. Also, here we are serializing the data using orjson, instead of regular JSON Just like the case with Django, you can initialize a Pymetrix object in the main.py file and then import into other scripts from there, if you want a centralized view. But you're also free to take a modular approach with your project by initializing the Pymetrix objects within each module - your skills are your limit.","title":"2. Using with FastAPI"},{"location":"#3-using-with-starlite","text":"Starlite is the new challenger in town for Web API frameworks. It's similar to FastAPI in the aspect that it's based on Starlette and Pydantic. But it has a fundamental philosophical difference - Starlite is opinionated, while FastAPI is not. According to the maker of Starlite, Na'aman Hirschfeld (who is also an online friend of mine \ud83d\ude0e): The intention behind Starlite was to create a higher level opinionated API framework. I placed opinionated in bold because in my view, being opinionated regarding how certain things should be done and shouldn\u2019t be done, and establishing best practices, is one of the most important things a framework can do. So let's see how Pymetrix works with Starlite: from starlite import Starlite , get from pymetrix import metrics , endpoints , flow from typing import Dict metricman = metrics . Metrics ( loc = \"Test\" ) @get ( path = \"/home\" ) def home () -> Dict : node1 : flow . FlowNodeType = flow . FlowNode ( endpoints . Endpoint ( endpoint = \"/home\" , id = home ), name = \"Home\" ) metricman . add_to_analytics ( node1 ) return { \"response\" : 200 , \"message\" : \"Home Page Works\" } @get ( path = \"/contact\" ) def contact () -> Dict : node2 : flow . FlowNodeType = flow . FlowNode ( endpoints . Endpoint ( endpoint = \"/contact\" , id = contact ), name = \"Contact\" ) metricman . add_to_analytics ( node2 ) return { \"response\" : 200 , \"message\" : \"Contact Page Works\" } @get ( path = \"/collaborations\" ) def collaborations () -> Dict : node3 : flow . FlowNodeType = flow . FlowNode ( endpoints . Endpoint ( endpoint = \"/collaborations\" , id = collaborations ), name = \"Collaborations\" , ) metricman . add_to_analytics ( node3 ) return { \"response\" : 200 , \"message\" : \"Collaborations Page Works\" } @get ( path = \"/events\" ) def events () -> Dict : node4 : flow . FlowNodeType = flow . FlowNode ( endpoints . Endpoint ( endpoint = \"/events\" , id = events ), name = \"Events\" ) metricman . add_to_analytics ( node4 ) return { \"response\" : 200 , \"message\" : \"Events Page Works\" } @get ( path = \"/blog\" ) def blog () -> Dict : node5 : flow . FlowNodeType = flow . FlowNode ( endpoints . Endpoint ( endpoint = \"/blog\" , id = blog ), name = \"Blog\" ) metricman . add_to_analytics ( node5 ) return { \"response\" : 200 , \"message\" : \"Blog Page Works\" } @get ( path = \"/about\" ) def about () -> Dict : node6 : flow . FlowNodeType = flow . FlowNode ( endpoints . Endpoint ( endpoint = \"/about\" , id = about ), name = \"About\" ) metricman . add_to_analytics ( node6 ) return { \"response\" : 200 , \"message\" : \"About Page Works\" } @get ( path = \"/statistics\" ) def statistics () -> Dict : node2 : flow . FlowNodeType = flow . FlowNode ( endpoints . Endpoint ( endpoint = \"/contact\" , id = contact ), name = \"Contact\" ) metricman . add_to_analytics ( node2 ) return { \"response\" : 200 , \"message\" : metricman . time_series ()} app = Starlite ( route_handlers = [ home , contact , collaborations , events , blog , about , statistics ] ) Do note that Starlite uses the orjson library for its responses by default.","title":"3. Using with Starlite"},{"location":"#orjson-note","text":"In orjson , the response is a JSON byte string and not a object. This dramatically speeds up the serialization process.","title":"Orjson Note"},{"location":"api/notes/","text":"Introduction Being the nascent library that it is at the moment, Pymetrix is by no means fully optimized. I am working actively on it, and any help is ABSOLUTELY WELCOME! \ud83d\ude01 That being said, these are some of my notes for getting the best results out of Pymetrix. 1. Time Series > Aggregate Time Series Data is a lot more meaningful than aggregated hits data. You can aggregate them over pipelines, stream them into databases... you are only limited by your imagination as to what you can do with them. Also, performance wise, Pymetrix processes and exports time series data faster than aggregated hits data. This is because the aggregation method is built atop the time series method. This essentially means that when you export your data in aggregated form, it is essentially doing the following things: Retrieve the time series data Aggregate the data according to the targets/endpoint names * Exporting the aggregated data Step 2 is the most tedious process, and is the extra step in aggregation. Being implemented in Python, it's a given that it'll be slow. Hence to speed up your workflow for large number of entries, exporting time series data is recommended. Also, time series data has a consistent format, which may not be the case with aggregated data, depending on which type of aggregation you want to do. * UPDATE : Now the basic hit count comes directly with the time series format. Still, what I told above still holds for other kind of aggregates. 2. Don't use pipeline() yet The pipeline() method is a method that'll greatly reduce your workload, and I am working actively on it. That being said, don't use it just yet - there are plenty of bugs in it, and I don't think that it'll be good for you to implement something into your code that's buggy. So please give me some time to work on it and use the time_series() and aggregate() methods instead.","title":"Notes"},{"location":"api/notes/#introduction","text":"Being the nascent library that it is at the moment, Pymetrix is by no means fully optimized. I am working actively on it, and any help is ABSOLUTELY WELCOME! \ud83d\ude01 That being said, these are some of my notes for getting the best results out of Pymetrix.","title":"Introduction"},{"location":"api/notes/#1-time-series-aggregate","text":"Time Series Data is a lot more meaningful than aggregated hits data. You can aggregate them over pipelines, stream them into databases... you are only limited by your imagination as to what you can do with them. Also, performance wise, Pymetrix processes and exports time series data faster than aggregated hits data. This is because the aggregation method is built atop the time series method. This essentially means that when you export your data in aggregated form, it is essentially doing the following things: Retrieve the time series data Aggregate the data according to the targets/endpoint names * Exporting the aggregated data Step 2 is the most tedious process, and is the extra step in aggregation. Being implemented in Python, it's a given that it'll be slow. Hence to speed up your workflow for large number of entries, exporting time series data is recommended. Also, time series data has a consistent format, which may not be the case with aggregated data, depending on which type of aggregation you want to do. * UPDATE : Now the basic hit count comes directly with the time series format. Still, what I told above still holds for other kind of aggregates.","title":"1. Time Series &gt; Aggregate"},{"location":"api/notes/#2-dont-use-pipeline-yet","text":"The pipeline() method is a method that'll greatly reduce your workload, and I am working actively on it. That being said, don't use it just yet - there are plenty of bugs in it, and I don't think that it'll be good for you to implement something into your code that's buggy. So please give me some time to work on it and use the time_series() and aggregate() methods instead.","title":"2. Don't use pipeline() yet"},{"location":"api/overview/","text":"Introduction Pymetrix can export two types of data: Time Series Aggregate in two types of modes: Snapshot Live Stream Data Types 1. Time Series Pymetrix can export time series data with the following format: { \"message\" : { \"id\" : \"Test\" , \"nodes\" : [ { \"callers\" : [ { \"caller\" : null , \"time\" : \"2022-01-09 18:26:51.410001\" } ], \"hits\" : 1 , \"id\" : \"Home\" , \"time\" : \"2022-01-09 18:26:51.409901\" }, { \"callers\" : [ { \"caller\" : null , \"time\" : \"2022-01-09 18:27:02.361461\" } ], \"hits\" : 1 , \"id\" : \"Blog\" , \"time\" : \"2022-01-09 18:27:02.361310\" }, ... ] }, \"response\" : 200 } which can be obtained by: calling the time_series() method iterating over the pipeline(data=\"time_series\", mode=\"live\") generator method, or calling the pipeline(data=\"time_series\", mode=\"snapshot\") method and accessing the values of the node key in the metricman object. Note that the pipeline() method is still buggy . 2. Aggregate Pymetrix can also export the aggregated hits data in the following format: { \"message\" : [ { \"hits\" : 1 , \"id\" : \"Home\" }, { \"hits\" : 1 , \"id\" : \"Blog\" } ... ], \"response\" : 200 } which can be obtained by: calling the aggregate() method iterating over the pipeline(data=\"aggregate\", mode=\"live\") generator method, or calling the pipeline(data=\"aggregate\", mode=\"snapshot\") method in the metricman object. Note that the pipeline() method is still buggy . Modes 1. Live This mode gives the live data of the targets. The live data can be either time series or aggregate. 2. Snapshot This mode gives the data of the targets UPTO the time when the method is called. As with the live mode, the data can be either time series or aggregate.","title":"Overview"},{"location":"api/overview/#introduction","text":"Pymetrix can export two types of data: Time Series Aggregate in two types of modes: Snapshot Live Stream","title":"Introduction"},{"location":"api/overview/#data-types","text":"","title":"Data Types"},{"location":"api/overview/#1-time-series","text":"Pymetrix can export time series data with the following format: { \"message\" : { \"id\" : \"Test\" , \"nodes\" : [ { \"callers\" : [ { \"caller\" : null , \"time\" : \"2022-01-09 18:26:51.410001\" } ], \"hits\" : 1 , \"id\" : \"Home\" , \"time\" : \"2022-01-09 18:26:51.409901\" }, { \"callers\" : [ { \"caller\" : null , \"time\" : \"2022-01-09 18:27:02.361461\" } ], \"hits\" : 1 , \"id\" : \"Blog\" , \"time\" : \"2022-01-09 18:27:02.361310\" }, ... ] }, \"response\" : 200 } which can be obtained by: calling the time_series() method iterating over the pipeline(data=\"time_series\", mode=\"live\") generator method, or calling the pipeline(data=\"time_series\", mode=\"snapshot\") method and accessing the values of the node key in the metricman object. Note that the pipeline() method is still buggy .","title":"1. Time Series"},{"location":"api/overview/#2-aggregate","text":"Pymetrix can also export the aggregated hits data in the following format: { \"message\" : [ { \"hits\" : 1 , \"id\" : \"Home\" }, { \"hits\" : 1 , \"id\" : \"Blog\" } ... ], \"response\" : 200 } which can be obtained by: calling the aggregate() method iterating over the pipeline(data=\"aggregate\", mode=\"live\") generator method, or calling the pipeline(data=\"aggregate\", mode=\"snapshot\") method in the metricman object. Note that the pipeline() method is still buggy .","title":"2. Aggregate"},{"location":"api/overview/#modes","text":"","title":"Modes"},{"location":"api/overview/#1-live","text":"This mode gives the live data of the targets. The live data can be either time series or aggregate.","title":"1. Live"},{"location":"api/overview/#2-snapshot","text":"This mode gives the data of the targets UPTO the time when the method is called. As with the live mode, the data can be either time series or aggregate.","title":"2. Snapshot"}]}